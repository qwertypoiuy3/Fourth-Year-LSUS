{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare two matrices as n dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is \n",
      "[[4 3]\n",
      " [2 1]]\n",
      "b is \n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[4, 3], [2, 1]])\n",
    "b = np.array([[1, 2], [3, 4]])\n",
    "print(\"a is \\n\" + str(a))\n",
    "print(\"b is \\n\" + str(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 5]\n",
      " [5 5]]\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 20]\n",
      " [ 5  8]]\n",
      "\n",
      " Another way is \n",
      "\n",
      "[[13 20]\n",
      " [ 5  8]]\n"
     ]
    }
   ],
   "source": [
    "print(a@b)\n",
    "print(\"\\n Another way is \\n\")\n",
    "print(np.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix elementwise multplication (Hadamard product) is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 6]\n",
      " [6 4]]\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose  $$a^{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3]\n",
      " [2 1]]\n",
      "[[4 2]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(np.transpose(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse (uses linalg)     $$a^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5  1.5]\n",
      " [ 1.  -2. ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.inv(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determinant of a is -2.0\n",
      "determinant of b is -2.0000000000000004\n",
      "condition number of a is 14.933034373659252\n",
      "condition number of b is 14.933034373659265\n"
     ]
    }
   ],
   "source": [
    "print(\"determinant of a is \" + str(np.linalg.det(a)) )\n",
    "print(\"determinant of b is \" + str(np.linalg.det(b)) )\n",
    "print(\"condition number of a is \" + str(np.linalg.cond(a)))\n",
    "print(\"condition number of b is \" + str(np.linalg.cond(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows ill conditioned matrices (condition number much higher than 1).\n",
    "Highly sensitive to small changes in input - bad for solving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  5.],\n",
       "       [-5., -6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is \n",
      "\n",
      "[[4 3]\n",
      " [2 1]]\n",
      "\n",
      " aa is \n",
      "\n",
      "[[5 3]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"a is \\n\")\n",
    "print(a)\n",
    "aa = np.array([[5, 3], [2, 1]])\n",
    "print(\"\\n aa is \\n\")\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small change in input leads to much larger change in output while solving.\n",
      "[[  8.  10.]\n",
      " [-13. -16.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Small change in input leads to much larger change in output while solving.\")\n",
    "print(np.linalg.solve(aa,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen values of a: \n",
      "[ 5.37228132 -0.37228132]\n",
      " and eigenvector of a: \n",
      "[[ 0.90937671 -0.56576746]\n",
      " [ 0.41597356  0.82456484]]\n"
     ]
    }
   ],
   "source": [
    "print(\"eigen values of a: \\n\" + str(np.linalg.eig(a)[0]) + \\\n",
    "     \"\\n and eigenvector of a: \\n\" + str(np.linalg.eig(a)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen values estimated from SVD are: \n",
      "[5.4649857  0.36596619]\n"
     ]
    }
   ],
   "source": [
    "(U,S,v) = np.linalg.svd(a)\n",
    "print(\"Eigen values estimated from SVD are: \")\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U and transpose of v from SVD are each estimated orthogional matrices $$ U . U^{T} \\approxeq I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -9.73614252e-17]\n",
      " [-9.73614252e-17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(U@np.transpose(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -1.72088383e-17]\n",
      " [-1.72088383e-17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(v@np.transpose(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U and v are analogous to rotation and S is analogous to stretching of the matrix.\n",
    "SVD is a closed-form solution which can be used for dimension reduction by choosing the top eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the original matrix a back from SVD estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3.]\n",
      " [2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(U@np.diag(S)@v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we used np.diag(S) and not S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.4649857 , 0.        ],\n",
       "       [0.        , 0.36596619]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithmic complexity of SVD remains high. So, in higher dimensions it is still not easy to compute: $$O(mn^2+m^2n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning methods such as gradient descent may be used to estimate in high dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there can be the curse of dimensionality (sparsity and meaningless distance) in high dimensional estimations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
